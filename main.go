package main

/*
In text networks, the words are the nodes and their co-occurrences are represented as arcs.
For example, using bigrams there is an arc between any two adjacent words in a text.

[=> no two distinct nodes for same word]

Assuming a unique final node (i.e., with no successor) is also present to represent the punctuation symbol ".",
let us call a "sentence" any path from a node to the final one.

[=> how to treat inner points? what about other punctuation?]

Write a concurrent sentence generator program in Google Go that takes a text in input and creates the corresponding text network,
with one goroutine for each node and communication channels for representing arcs.

Then, sentences are generated by sending a suitable message to some node.

[metrics?]
*/

import (
	"flag"
	"fmt"
	"io"
	"log"
	"os"
	"runtime/pprof"
	"strings"
	"time"
	"unicode"

	"golang.design/x/chann"
)


func Assert(condition bool, msg string) {
	if !condition {
		log.Fatalf("Assertion failed: %s", msg)
	}
}

func TrimPunctuation(s string) string {
	return strings.TrimFunc(s, func(r rune) bool {
		return unicode.IsPunct(r)
	})
}


func main() {
	log.SetOutput(io.Discard)	//enable/disable logging

	file_path := flag.String("file", "", "the path of the file to analyze")
	max_depth := flag.Int("max_depth", 1, "maximum depth of the generated sentence")
	export_graph := flag.Bool("export_graph", false, "enable to export the text network in .dot")
	print_sentences := flag.Bool("print_sentences", false, "enable to print all the generated sentences")
	seq := flag.Bool("seq", false, "generate in sequential mode")


	cpuprofile := flag.String("cpuprofile", "", "write cpu profile to file")
	memprofile := flag.String("memprofile", "", "write memory profile to file")
	
	flag.Parse()

	if *cpuprofile != "" {
        f, err := os.Create(*cpuprofile)
        if err != nil {
            log.Fatal(err)
        }
        pprof.StartCPUProfile(f)
        defer pprof.StopCPUProfile()
    }

	text := ParseFile(*file_path)
	sentences := strings.Split(strings.TrimSpace(text), ".")

	var tokens [][]string

	for _, sent := range sentences {
		if sent != "" {
			normalized_sent := strings.TrimSpace(sent) //remove spaces around sentence
			tokens = append(tokens, strings.Split(normalized_sent, " "))
		}
	}
	
	//GRAPH BUILDING
	graph := NewGraph()
	graph.AddNode(".")
	
	for _, sent_tokens := range tokens {
		for _, el := range sent_tokens {
			el = TrimPunctuation(el)
			if graph.nodes[el] == nil {
				graph.AddNode(el)
				log.Printf("Adding node %s\n", el)
			}
		}

		for i, el := range sent_tokens {
			el = TrimPunctuation(el)
			if i < len(sent_tokens) - 1 {
				next := TrimPunctuation(sent_tokens[i+1])
				graph.AddEdge(el, next)	//add bigram as edge
				log.Printf("Adding edge %s -> %s ", el,sent_tokens[i+1])			
			} else {
				graph.AddEdge(sent_tokens[i], ".")
				log.Printf("Adding edge %s -> .\n ", sent_tokens[i])
			}
		}
	}

	if *export_graph {
		go func() {
			graph_file := "./graph.dot"
			err := os.WriteFile(graph_file, []byte(graph.ToDot()), 0644)
			if err != nil {
				os.Remove(graph_file)
			}
		}()
	}


    
	//SENTENCE GENERATION
	start := time.Now()
	
	resultCh := chann.New[Message]()//make(chan Message, 1000)
	
	if *seq {
		SeqStrategy(*graph, *max_depth, resultCh)
	} else {
		ParStrategy(*graph, *max_depth, resultCh)
	}

	resultCh.Close()
	

	end := time.Now()
	elapsed := end.Sub(start)

	// Collect results
	if *print_sentences{
		i := 0
		for res:= range resultCh.Out() {
			fmt.Println(strings.Join(res.sentence, " "))
			i++
		}
		fmt.Println("#sentences:", i)
	}
	

	fmt.Println("Sentence generation took:", elapsed)

	//Free graph
	for _, node := range graph.nodes {
		node.input.Close()
	}

	if *memprofile != "" {
        f, err := os.Create(*memprofile)
        if err != nil {
            log.Fatal(err)
        }
        pprof.WriteHeapProfile(f)
        f.Close()
        return
    }
}
