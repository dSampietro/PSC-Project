package main

/*
In text networks, the words are the nodes and their co-occurrences are represented as arcs.
For example, using bigrams there is an arc between any two adjacent words in a text.

[=> no two distinct nodes for same word]

Assuming a unique final node (i.e., with no successor) is also present to represent the punctuation symbol ".",
let us call a "sentence" any path from a node to the final one.

[=> how to treat inner points? what about other punctuation?]

Write a concurrent sentence generator program in Google Go that takes a text in input and creates the corresponding text network,
with one goroutine for each node and communication channels for representing arcs.

Then, sentences are generated by sending a suitable message to some node.

[metrics?]
*/

import (
	"fmt"
	"io"
	"log"
	"strings"
	"sync"
	"sync/atomic"
	"time"
	"unicode"
)


func Assert(condition bool, msg string) {
	if !condition {
		log.Fatalf("Assertion failed: %s", msg)
	}
}

func TrimPunctuation(s string) string {
	return strings.TrimFunc(s, func(r rune) bool {
		return unicode.IsPunct(r)
	})
}


func main() {
	log.SetOutput(io.Discard)	//enable/disable logging
	
	text := ParseFile("example_cycle.txt")
	fmt.Println(text)

	sentences := strings.Split(strings.TrimSpace(text), ".")
	fmt.Println(sentences)

	var tokens [][]string

	for _, sent := range sentences {
		if sent != "" {
			//fmt.Printf("sentence: '%s'\n", sent)
			normalized_sent := strings.TrimSpace(sent) //remove spaces around sentence
			tokens = append(tokens, strings.Split(normalized_sent, " "))
		}
	}

	//compute min value of N
	max_string_len := 0
	for _, tok := range tokens {
		max_string_len = max(max_string_len, len(tok))
	}
	fmt.Printf("max_string_len: %d\n", max_string_len)

	
	//GRAPH BUILDING
	graph := NewGraph()
	graph.AddNode(".")
	
	for _, sent_tokens := range tokens {
		for _, el := range sent_tokens {
			el = TrimPunctuation(el)
			if graph.nodes[el] == nil {
				graph.AddNode(el)
				log.Printf("Adding node %s\n", el)
			}
		}

		for i, el := range sent_tokens {
			el = TrimPunctuation(el)
			if i < len(sent_tokens) - 1 {
				next := TrimPunctuation(sent_tokens[i+1])
				graph.AddEdge(el, next)	//add bigram as edge
				log.Printf("Adding edge %s -> %s ", el,sent_tokens[i+1])			
			} else {
				graph.AddEdge(sent_tokens[i], ".")
				log.Printf("Adding edge %s -> .\n ", sent_tokens[i])
			}
		}
	}

	graph.PrettyPrint()


    
	//SENTENCE GENERATION
	var wg sync.WaitGroup
	resultCh := make(chan Message, 1000)

	start := time.Now()

	/*for _, node := range graph.nodes {
		node.GenerateSenetence(&wg, resultCh, 10, 10)
	}
	*/

	// Setup channel with initial value DFS from each node
	for _, node := range graph.nodes {
		node.GenerateSenetence(&wg, resultCh, 20, 20)

		if node.label == "." { continue }
		wg.Add(1)
		
		msg := Message {
			sentence: fmt.Sprintf("[FROM %s]", node.label),
			visited: map[*Node]int{node: 1},
			depth: 0,
		}
		node.input <- msg // Start traversal with empty message
	}


	// Wait for all paths to finish
	go func() {
		wg.Wait()
		close(resultCh)
	}()

	t := time.Now()
	elapsed := t.Sub(start)

	// Collect results
	i := 0
	for res := range resultCh {
		fmt.Println(res.sentence)
		i++
	}
	fmt.Println("#sentences:", i)

	fmt.Println("Sentence generation took:", elapsed)
	fmt.Printf("Peak inâ€flight messages: %d\n", atomic.LoadInt64(&maxInFlight))

}
