package main

/*
In text networks, the words are the nodes and their co-occurrences are represented as arcs.
For example, using bigrams there is an arc between any two adjacent words in a text.

[=> no two distinct nodes for same word]

Assuming a unique final node (i.e., with no successor) is also present to represent the punctuation symbol ".",
let us call a "sentence" any path from a node to the final one.

[=> how to treat inner points? what about other punctuation?]

Write a concurrent sentence generator program in Google Go that takes a text in input and creates the corresponding text network,
with one goroutine for each node and communication channels for representing arcs.

Then, sentences are generated by sending a suitable message to some node.

[metrics?]
*/

import (
	"fmt"
	"log"
	"strings"
	"sync"
	"time"
	"unicode"
)


func Assert(condition bool, msg string) {
	if !condition {
		log.Fatalf("Assertion failed: %s", msg)
	}
}

func TrimPunctuation(s string) string {
	return strings.TrimFunc(s, func(r rune) bool {
		return unicode.IsPunct(r)
	})
}

func PrettyPrint(graph map[string]*Node){

	fmt.Println("digraph {")
	for _, node := range graph {
		if node.successors != nil {
			for _, succ  := range node.successors {
				fmt.Printf("\t%s -> %s\n", node.label, succ.label)
			}
		}
	}
	fmt.Printf("}\n")
}


func main() {
	text := ParseFile("example.txt")
	fmt.Println(text)

	sentences := strings.Split(strings.TrimSpace(text), ".")
	fmt.Println(sentences)

	var tokens [][]string

	for _, sent := range sentences {
		if sent != "" {
			//fmt.Printf("sentence: '%s'\n", sent)
			normalized_sent := strings.TrimSpace(sent) //remove spaces around sentence
			tokens = append(tokens, strings.Split(normalized_sent, " "))
		}
	}

	fmt.Println(tokens)

	//all_tokens := slices.Concat(tokens...) 
	//fmt.Println(all_tokens)
	
	//GRAPH BUILDING

	nodes := map[string]*Node{}
	nodes["."] = NewNode(".")
	
	//TODO: reverse building: start from last, add prev + edges
	for _, sent_tokens := range tokens{
		//add nodes
		for _, el := range sent_tokens {
			el = TrimPunctuation(el)
			if nodes[el] == nil {
				nodes[el] = NewNode(el)
				log.Printf("Adding node %s\n", el)
			}
		}
		
		for i, el := range sent_tokens {
			el = TrimPunctuation(el)
			if i < len(sent_tokens) - 1 {
				next := TrimPunctuation(sent_tokens[i+1])
				nodes[el].successors = append(nodes[el].successors, nodes[next])	//add bigram as edge
				log.Printf("Adding edge %s -> %s ", el,sent_tokens[i+1])			
			} else {
				nodes[sent_tokens[i]].successors = []*Node{nodes["."]}
				log.Printf("Adding edge %s -> .\n ", sent_tokens[i])

			}
		}
	} 

	PrettyPrint(nodes)



	//SENTENCE GENERATION
	var wg sync.WaitGroup
	resultCh := make(chan string)

	start := time.Now()

	// Setup channel with initial value DFS from each node
	for _, node := range nodes {
		wg.Add(1)
		node.input <- fmt.Sprintf("[FROM %s]",node.label) // Start traversal with empty message
	}


	for _, node := range nodes {
		node.GenerateSenetence(&wg, resultCh)
	}



	// Wait for all paths to finish
	go func() {
		wg.Wait()
		close(resultCh)
	}()

	t := time.Now()
	elapsed := t.Sub(start)
	fmt.Println(elapsed)

	// Collect results
	i := 0
	for res := range resultCh {
		fmt.Println(res)
		i++
	}


	//fmt.Printf("#visits: %d\n#nodes: %d\n", i, len(txt))
	//Assert(i == len(txt), "#visits")
	
}
