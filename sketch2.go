package main

/*
In text networks, the words are the nodes and their co-occurrences are represented as arcs.
For example, using bigrams there is an arc between any two adjacent words in a text.

[=> no two distinct nodes for same word]

Assuming a unique final node (i.e., with no successor) is also present to represent the punctuation symbol ".",
let us call a "sentence" any path from a node to the final one.

[=> how to treat inner points? what about other punctuation?]

Write a concurrent sentence generator program in Google Go that takes a text in input and creates the corresponding text network,
with one goroutine for each node and communication channels for representing arcs.

Then, sentences are generated by sending a suitable message to some node.

[metrics?]
*/

import (
	"flag"
	"fmt"
	"io"
	"log"
	"os"
	"runtime/pprof"
	"strings"
	"sync"
	"time"
	"unicode"

	"golang.design/x/chann"
)


func Assert(condition bool, msg string) {
	if !condition {
		log.Fatalf("Assertion failed: %s", msg)
	}
}

func TrimPunctuation(s string) string {
	return strings.TrimFunc(s, func(r rune) bool {
		return unicode.IsPunct(r)
	})
}


func main() {
	log.SetOutput(io.Discard)	//enable/disable logging

	file_path := flag.String("file", "", "the path of the file to analyze")
	//node_limit := flag.Int("node_limit", 10, "how many times a sentence can use a node")
	max_depth := flag.Int("max_depth", 10, "maximum depth of the generated sentence")
	export_graph := flag.Bool("export_graph", false, "enable to export the text network in .dot")
	print_sentences := flag.Bool("print_sentences", false, "enable to print all the generated sentences")
	export_sentences := flag.Bool("export_sentences", false, "enable to export the generated sentences")
	//seq := flag.Bool("seq", false, "generate in sequential mode")


	cpuprofile := flag.String("cpuprofile", "", "write cpu profile to file")
	memprofile := flag.String("memprofile", "", "write memory profile to this file")
	
	flag.Parse()

	if *cpuprofile != "" {
        f, err := os.Create(*cpuprofile)
        if err != nil {
            log.Fatal(err)
        }
        pprof.StartCPUProfile(f)
        defer pprof.StopCPUProfile()
    }



	text := ParseFile(*file_path)
	//fmt.Println(text)

	sentences := strings.Split(strings.TrimSpace(text), ".")
	//fmt.Println(sentences)

	var tokens [][]string

	for _, sent := range sentences {
		if sent != "" {
			//fmt.Printf("sentence: '%s'\n", sent)
			normalized_sent := strings.TrimSpace(sent) //remove spaces around sentence
			tokens = append(tokens, strings.Split(normalized_sent, " "))
		}
	}

	/*
	//compute min value of N
	max_string_len := 0
	for _, tok := range tokens {
		max_string_len = max(max_string_len, len(tok))
	}
	fmt.Printf("max_string_len: %d\n", max_string_len)
	*/
	
	//GRAPH BUILDING
	graph := NewGraph()
	graph.AddNode(".")
	
	for _, sent_tokens := range tokens {
		for _, el := range sent_tokens {
			el = TrimPunctuation(el)
			if graph.nodes[el] == nil {
				graph.AddNode(el)
				log.Printf("Adding node %s\n", el)
			}
		}

		for i, el := range sent_tokens {
			el = TrimPunctuation(el)
			if i < len(sent_tokens) - 1 {
				next := TrimPunctuation(sent_tokens[i+1])
				graph.AddEdge(el, next)	//add bigram as edge
				log.Printf("Adding edge %s -> %s ", el,sent_tokens[i+1])			
			} else {
				graph.AddEdge(sent_tokens[i], ".")
				log.Printf("Adding edge %s -> .\n ", sent_tokens[i])
			}
		}
	}

	//fmt.Println(graph.ToDot())

	if *export_graph {
		go func() {
			graph_file := "./graph.dot"
			err := os.WriteFile(graph_file, []byte(graph.ToDot()), 0644)
			if err != nil {
				os.Remove(graph_file)
			}
		}()
	}


    
	//SENTENCE GENERATION
	var wg sync.WaitGroup
	resultCh := chann.New[Message]()//make(chan Message, 1000)

	start := time.Now()

	// Setup channel with initial value DFS from each node
	for _, node := range graph.nodes {
		// we guarantee one goroutine/node => no unbounded goroutines
		node.GenerateSentence(&wg, resultCh.In(), *max_depth)

		if node.label == "." { continue }
		wg.Add(1)
		
		msg := Message {
			//sentence: fmt.Sprintf("[FROM %s]", node.label),
			sentence: []string{fmt.Sprintf("[FROM %s]", node.label)},
			//visited: map[string]int{node.label: 1},
			depth: 0,
		}
		node.input.In() <- msg // Start traversal with empty message
	}


	// Wait for all paths to finish
	wg.Wait()
	resultCh.Close()
	

	end := time.Now()
	elapsed := end.Sub(start)

	// Collect results
	if *print_sentences{
		i := 0
		for res := range resultCh.Out() {
			fmt.Println(strings.Join(res.sentence, " "))
			i++
		}
		fmt.Println("#sentences:", i)
	}
	

	fmt.Println("Sentence generation took:", elapsed)

	//Free graph
	for _, node := range graph.nodes {
		node.input.Close()
	}

	//TODO: write senteces to output file
	if *export_sentences {}

	if *memprofile != "" {
        f, err := os.Create(*memprofile)
        if err != nil {
            log.Fatal(err)
        }
        pprof.WriteHeapProfile(f)
        f.Close()
        return
    }
}
